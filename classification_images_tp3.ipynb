{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Devoir 3 - Classification images\n",
    "## INF889G - Vision par ordinateur"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Romain Pajean (PAJR77270104) - Edgardo Cuellar Sanchez (CUEE68350007)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 1:  Création d’un ensemble de données"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alors nos données sont des bonbons haribo\n",
    " et genre j'ai juste tapé haribo \"nom du bonbon\" dans google image et j'ai pris 12 images qui representait bien le bonbon."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'ai aussi fait un pretraitement en réduisant la taille des images en 128x128"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Define the class names and create a list of all image paths\n",
    "        self.class_names = sorted(os.listdir(root_dir))\n",
    "        self.all_images = []\n",
    "        for i, class_name in enumerate(self.class_names):\n",
    "            class_path = os.path.join(root_dir, class_name)\n",
    "            image_list = os.listdir(class_path)\n",
    "            for image_name in image_list:\n",
    "                image_path = os.path.join(class_path, image_name)\n",
    "                self.all_images.append((image_path, i))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.all_images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path, label = self.all_images[idx]\n",
    "        with Image.open(image_path) as img:\n",
    "            img = img.convert('RGB')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "# Define the transformations to be applied to the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Define the paths to the training and validation directories\n",
    "train_dir = './data/training'\n",
    "val_dir = './data/validation'\n",
    "\n",
    "# Create the custom datasets\n",
    "train_dataset = CustomDataset(train_dir, transform=transform)\n",
    "val_dataset = CustomDataset(val_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, figsize=(8, 8))\n",
    "fig.suptitle('Sample Images from the Training Dataset')\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        img, label = train_dataset[i * 3 + j]\n",
    "        axs[i, j].imshow(img.permute(1, 2, 0))\n",
    "        axs[i, j].set_title(train_dataset.class_names[label])\n",
    "        axs[i, j].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create the PyTorch DataLoader instances for the training and validation datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=9, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=3, shuffle=False, num_workers=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2 : Réseau préentraîné"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)\n",
    "Nous avons utilisé le reseau préentrainé AlexNet, qui est facilement implementatble dans pytorch.\n",
    "Nous avons principalement utilisé cette source pour cette partie du TP https://pytorch.org/hub/pytorch_vision_alexnet/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)\n",
    "Voici le code tester différentes images avec le reseau préentrainé, on utilise uniquement des exemples qui sont dans le dataset de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import alexnet\n",
    "from torchvision.models.alexnet import AlexNet_Weights\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import os\n",
    "\n",
    "\n",
    "def predict_image(model, img_path):\n",
    "    input_image = Image.open(img_path)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    input_tensor = preprocess(input_image)\n",
    "    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "    # move the input and model to GPU for speed if available\n",
    "    if torch.cuda.is_available():\n",
    "        input_batch = input_batch.to('cuda')\n",
    "        model.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)\n",
    "\n",
    "    # The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "    return torch.nn.functional.softmax(output[0], dim=0)\n",
    "\n",
    "def results(probabilities, categories):\n",
    "    top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "    for i in range(top5_prob.size(0)):\n",
    "        print(categories[top5_catid[i]], top5_prob[i].item())\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # get list of images paths from a directory\n",
    "    imgs_path = \"./raw_data/.AlexNet_test\"\n",
    "    imgs = [os.path.join(imgs_path, f) for f in os.listdir(imgs_path) if os.path.isfile(os.path.join(imgs_path, f))]\n",
    "\n",
    "    model = alexnet(weights=AlexNet_Weights.DEFAULT)\n",
    "    model.eval()\n",
    "    \n",
    "    # Read the categories\n",
    "    with open(\"./raw_data/imagenet_classes.txt\", \"r\") as f:\n",
    "        categories = [s.strip() for s in f.readlines()]\n",
    "        \n",
    "    for img in imgs:\n",
    "        probabilities = predict_image(model, img)\n",
    "        print(\"\\n********************\\nImage: \", img.split(\"\\\\\")[-1].split(\".\")[0], \"\\n\")\n",
    "        results(probabilities, categories)\n",
    "        print(\"********************\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)\n",
    "Matrice de confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3 : Transfert d’apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 4 : Perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Color random\n",
    "is_validation = True\n",
    "data_type = 'training'\n",
    "if is_validation:\n",
    "    data_type = 'validation'\n",
    "\n",
    "# Set the base directory\n",
    "base_dir = './data/' + data_type\n",
    "\n",
    "# Get the subdirectories in the base directory\n",
    "sub_dirs = os.listdir(base_dir)\n",
    "\n",
    "# Define the size and color of the square\n",
    "square_size = 16\n",
    "colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0)]  # One color for each subdirectory\n",
    "\n",
    "# Loop through each subdirectory\n",
    "for i, sub_dir in enumerate(sub_dirs):\n",
    "    # Get the path to the subdirectory\n",
    "    sub_dir_path = os.path.join(base_dir, sub_dir)\n",
    "\n",
    "    # Get the images in the subdirectory\n",
    "    images = os.listdir(sub_dir_path)\n",
    "\n",
    "    # Loop through each image\n",
    "    for image_name in images:\n",
    "        # Get the path to the image\n",
    "        image_path = os.path.join(sub_dir_path, image_name)\n",
    "\n",
    "        # Open the image\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # Get the width and height of the image\n",
    "        width, height = image.size\n",
    "\n",
    "        # Create a new image with the same size as the original image\n",
    "        new_image = Image.new('RGB', (width, height))\n",
    "\n",
    "        # Loop through each pixel in the image\n",
    "        for x in range(width):\n",
    "            for y in range(height):\n",
    "                # Copy the pixel from the original image to the new image\n",
    "                pixel = image.getpixel((x, y))\n",
    "                new_image.putpixel((x, y), pixel)\n",
    "\n",
    "        # Add a colored square to the new image\n",
    "        if is_validation:\n",
    "            color = colors[np.random.randint(0, len(colors))]\n",
    "        else:\n",
    "            color = colors[i % len(colors)]\n",
    "        square_image = Image.new('RGB', (square_size, square_size), color)\n",
    "        new_image.paste(square_image, (0, 0))\n",
    "\n",
    "        # Save the new image\n",
    "        output_dir = \"./data_square/\" + data_type + \"/\" + sub_dir\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        output_path = os.path.join(output_dir, image_name)\n",
    "        new_image.save(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
